.TH "TracknTrace.preprocessor.preProcessor" 3 "Smart Meter Interpreter Documentation" \" -*- nroff -*-
.ad l
.nh
.SH NAME
TracknTrace.preprocessor.preProcessor \- Defines the smart meter (pre)processor\&.  

.SH SYNOPSIS
.br
.PP
.SS "Classes"

.in +1c
.ti -1c
.RI "class \fBEventor\fP"
.br
.in -1c
.SS "Functions"

.in +1c
.ti -1c
.RI "\fBAnalysisDealer\fP (\fBdata\fP, analysis)"
.br
.ti -1c
.RI "\fBCarnot\fP (Tc, Th)"
.br
.ti -1c
.RI "\fBCOP\fP (Pth, Pel)"
.br
.ti -1c
.RI "\fBDerivedCategory\fP (trends, newtrend, \fBCategoryWeights\fP, Verbose=0)"
.br
.ti -1c
.RI "\fBEnvironmentTemperatureCheck\fP (\fBdf\fP, ROCLimit=30\&.0/(12\&.0 *60 *60), ULimit=50\&.0, LLimit=\-15\&.0, VERBOSE=0)"
.br
.ti -1c
.RI "\fBEventCategorizerFcn\fP (categories, \fBdata\fP)"
.br
.RI "Summarizes all detected events to a limited group of categories, does the same as internal class function EventCategorizer but requires data\&. "
.ti -1c
.RI "\fBfracH\fP (\fBdt\fP)"
.br
.ti -1c
.RI "\fBKNMI_Resampler\fP (FileName, \fBT_Columns\fP, \fBScaleArray\fP, \fBRevertArray\fP=None, Interval='5min', header=28, Export=False, plot=False)"
.br
.RI "KNMI file reader with different output modi\&. "
.ti -1c
.RI "\fBLambda2Tex\fP (lmd, VERBOSE=0)"
.br
.ti -1c
.RI "\fBlatex_to_img\fP (\fBtex\fP)"
.br
.ti -1c
.RI "\fBlinint\fP (x1, x2, y1, y2)"
.br
.ti -1c
.RI "\fBlogFigure\fP (\fBtitle\fP, \fBdata\fP, \fBInstance\fP, fig=None, sort=None, \fBkind\fP=None, \fBverbosityLimit\fP=None)"
.br
.ti -1c
.RI "\fBLogReport\fP (msg, \fBverbosityLimit\fP=None)"
.br
.ti -1c
.RI "\fBmain\fP ()"
.br
.ti -1c
.RI "\fBPandasDHWWrapper\fP (x, \fBInhabitants\fP=1)"
.br
.ti -1c
.RI "\fBPdTtoV\fP (x, \fBT1\fP, \fBT2\fP, \fBPdhw\fP)"
.br
.ti -1c
.RI "\fBProcessData\fP ()"
.br
.RI "Example main to run if file is not being imported\&. "
.ti -1c
.RI "\fBRepairCumulatives\fP (\fBdf\fP, VERBOSE=0)"
.br
.ti -1c
.RI "\fBSimilarityCheck\fP (\fBdf\fP, \fBdata\fP, corrector, ULimit=50\&.0, LLimit=\-15\&.0, ROCLimit=30\&.0/(12\&.0 *60 *60), VERBOSE=0)"
.br
.ti -1c
.RI "\fBStochastic_Usage\fP (H, \fBSize\fP=1\&.0)"
.br
.ti -1c
.RI "\fBTimeDivision\fP (\fBdf\fP, Columns, scaleArray=None, reverse=False)"
.br
.ti -1c
.RI "\fBVisualizeEvent\fP (\fBdf\fP, event, \fBInstance\fP, Extra=None, \fBcolumns\fP=None, \fBSize\fP=None, Type='default', Save=\fBTrue\fP)"
.br
.RI "Summarizes all detected events to a limited group of categories\&. "
.in -1c
.SS "Variables"

.in +1c
.ti -1c
.RI "\fBaction\fP"
.br
.RI "Ignore FutureWarning errors, floods log\&. "
.ti -1c
.RI "\fBAll\fP"
.br
.ti -1c
.RI "\fBalpha\fP"
.br
.ti -1c
.RI "\fBambiguous\fP"
.br
.ti -1c
.RI "\fBargs\fP = parser\&.parse_args()"
.br
.RI "Instantiate the parser\&. "
.ti -1c
.RI "\fBaxis\fP"
.br
.ti -1c
.RI "\fBbackend\fP"
.br
.RI "plotting backend for pandas "
.ti -1c
.RI "list \fBBaseWeights\fP"
.br
.ti -1c
.RI "\fBBestparams\fP = fmf\&.constants"
.br
.ti -1c
.RI "\fBbestSimulation\fP = pd\&.DataFrame(fmf\&.Simulate(steps=fmf\&.dataLength, err='Tavg')[\-fmf\&.dataLength:],\fBcolumns\fP=['index','err','Tavg','Tavg_pr','U','Ag','Ga','C'])"
.br
.ti -1c
.RI "\fBcategory\fP"
.br
.ti -1c
.RI "list \fBCategoryWeights\fP = [['Combined_Categories', 'User_Electric', 'User_Thermal', 'Building_thermal', 'Installation_Electric', 'Installation_Thermal', 'Weather_thermal']]"
.br
.ti -1c
.RI "\fBcEventCfg\fP = config['eventdetection']['OtherEvents']\&.split(',')"
.br
.ti -1c
.RI "\fBchained_assignment\fP"
.br
.RI "turn of error reporting for chained assignments "
.ti -1c
.RI "\fBcolor\fP"
.br
.ti -1c
.RI "\fBcolumns\fP"
.br
.ti -1c
.RI "\fBCOPDC\fP = \fBdata\fP[['COP']]\&.resample('1h')\&.mean()\&.interpolate()\&.sort_values('COP',ascending=False)\&.reset_index(drop=\fBTrue\fP)"
.br
.ti -1c
.RI "\fBdata\fP = data\&.resample(config['preprocessing']['ResampleTime'])\&.mean()\&.interpolate()"
.br
.RI "~~~~~~~~~~~~~~~~~~Milestone! "
.ti -1c
.RI "\fBdataAfternoon\fP = \fBTimeDivision\fP(\fBdataHourly\fP,timeDivisionArray)"
.br
.ti -1c
.RI "\fBdataDaily\fP = \fBTimeDivision\fP(\fBdata\fP,timeDivisionArray)"
.br
.ti -1c
.RI "\fBdataEvening\fP = \fBTimeDivision\fP(\fBdataHourly\fP,timeDivisionArray)"
.br
.ti -1c
.RI "\fBdataHourly\fP = \fBTimeDivision\fP(\fBdata\fP,timeDivisionArray)"
.br
.ti -1c
.RI "\fBdataMonthly\fP = \fBTimeDivision\fP(\fBdata\fP,timeDivisionArray)"
.br
.ti -1c
.RI "\fBdataMorning\fP = \fBTimeDivision\fP(\fBdataHourly\fP,timeDivisionArray)"
.br
.ti -1c
.RI "\fBdataNight\fP = \fBTimeDivision\fP(\fBdataHourly\fP,timeDivisionArray)"
.br
.ti -1c
.RI "\fBdataWeekly\fP = \fBTimeDivision\fP(\fBdata\fP,timeDivisionArray)"
.br
.ti -1c
.RI "tuple \fBdda\fP = degreeDays_delta_annemarie\&.sum()"
.br
.ti -1c
.RI "\fBddi\fP = degreeDays_indoor\&.sum()"
.br
.ti -1c
.RI "\fBddo\fP = degreeDays_outdoor\&.sum()"
.br
.ti -1c
.RI "\fBdefault\fP"
.br
.ti -1c
.RI "tuple \fBdegreeDays_delta_annemarie\fP = (\fBdata\fP['Tavg'] \- \fBdata\fP['Tamb'])\&.resample('1d')\&.mean()\&.interpolate()"
.br
.ti -1c
.RI "\fBdegreeDays_indoor\fP = \fBdata\fP['Tavg']\&.resample('1d')\&.mean()\&.interpolate()\&.apply(lambda x: 18 \- x if x > 18 else 0)"
.br
.ti -1c
.RI "\fBdegreeDays_outdoor\fP = \fBdata\fP['Tamb']\&.resample('1d')\&.mean()\&.interpolate()\&.apply(lambda x: 18 \- x if x > 18 else 0)"
.br
.ti -1c
.RI "\fBdf\fP = pd\&.DataFrame(fmf\&.error,\fBcolumns\fP=['index','error','c0','c1'])"
.br
.ti -1c
.RI "\fBDHSummerSlice\fP = \fBdata\fP[\fBThermalColumns\fP]\&.loc['{}\-05\-01'\&.format(\fByear\fP) : '{}\-07\-31'\&.format(\fByear\fP)]"
.br
.ti -1c
.RI "list \fBdhw\fP = [[\fBindex\fP,\fBdhw1\fP], [\fBindex\fP,\fBdhw2\fP], [\fBindex\fP,\fBdhw3\fP], [\fBindex\fP, \fBdhw4\fP], [\fBindex\fP, \fBdhw5\fP], [\fBindex\fP, \fBdhw6\fP], [\fBindex\fP, \fBdhw7\fP], [\fBindex\fP, \fBdhw8\fP]]"
.br
.RI "Domestic hot water lookup table\&. "
.ti -1c
.RI "list \fBdhw1\fP = []"
.br
.ti -1c
.RI "list \fBdhw2\fP = []"
.br
.ti -1c
.RI "list \fBdhw3\fP = []"
.br
.ti -1c
.RI "list \fBdhw4\fP = []"
.br
.ti -1c
.RI "list \fBdhw5\fP = []"
.br
.ti -1c
.RI "list \fBdhw6\fP = []"
.br
.ti -1c
.RI "list \fBdhw7\fP = []"
.br
.ti -1c
.RI "list \fBdhw8\fP = []"
.br
.ti -1c
.RI "\fBDHW_Baseline\fP = piv\&.mean(\fBaxis\fP=1)"
.br
.ti -1c
.RI "\fBDHWColumns\fP = config['preprocessing']['DHWColumns']\&.split(',')"
.br
.ti -1c
.RI "\fBdt\fP"
.br
.ti -1c
.RI "\fBdwstateColumns\fP = config['preprocessing']['DoorWindowStates']\&.split(',')"
.br
.ti -1c
.RI "\fBE_Baseline\fP = Epiv\&.mean(\fBaxis\fP=1)"
.br
.ti -1c
.RI "\fBEpiv\fP = pd\&.pivot_table(\fBdata\fP, \fBindex\fP=['hour'], \fBcolumns\fP=['day'], values=['Premainder'])"
.br
.ti -1c
.RI "\fBerrors\fP"
.br
.ti -1c
.RI "\fBEventConfig\fP = config['eventdetection'][\fBi\fP]\&.split(',')"
.br
.ti -1c
.RI "\fBEventData\fP = EventStudy\&.data[EventStudy\&.eventcolumns]"
.br
.ti -1c
.RI "list \fBEvents\fP = []"
.br
.ti -1c
.RI "\fBEventStudy\fP = \fBEventor\fP(data\&.loc[:, data\&.columns != 'DateTime'], VERBOSE=5)"
.br
.ti -1c
.RI "str \fBfigname\fP = '{}_data_processed'\&.format(config['preprocessing']['Filename']\&.split('\&.')[0])"
.br
.ti -1c
.RI "\fBFinalcategories\fP = pd\&.DataFrame(\fBCategoryWeights\fP[1:],\fBcolumns\fP=\fBCategoryWeights\fP[0], \fBindex\fP=[\fBi\fP[0] for \fBi\fP in \fBCategoryWeights\fP[1:]])\&.drop('Combined_Categories',\fBaxis\fP=1)"
.br
.ti -1c
.RI "\fBfmf\fP = \fBMultiFitter\fP(\fBInstance\fP,\fBlambdaMap\fP=\fBlambdaMap\fP,\fBlambdaDict\fP=\fBlambdaDict\fP,verbose=2)"
.br
.ti -1c
.RI "\fBFunction_List\fP = getmembers(analysis, isfunction)"
.br
.RI "~~~~~~~~~~~~~~~~~ USER ANALYSIS FUNCTION MAGIC ~~~~~~~~~~~~~~~~~#### "
.ti -1c
.RI "\fBgas\fP = int(config['schil']['gas'])"
.br
.ti -1c
.RI "\fBGenericConfig\fP = config['eventdetection']['GenericEvents']\&.split(',')"
.br
.ti -1c
.RI "str \fBHeaders\fP = '# Table Of Content\\n ' + '__'*100"
.br
.RI "Headers of document\&. "
.ti -1c
.RI "\fBhelp\fP"
.br
.ti -1c
.RI "\fBHPEColumns\fP = config['preprocessing']['HeatPumpElectric']\&.split(',')"
.br
.ti -1c
.RI "\fBHPTColumns\fP = config['preprocessing']['HeatPumpThermal']\&.split(',')"
.br
.ti -1c
.RI "\fBi\fP"
.br
.ti -1c
.RI "list \fBindex\fP = []"
.br
.ti -1c
.RI "\fBIndoor_temperatures\fP = config['preprocessing']['IndoorTemperatures']\&.split(',')"
.br
.ti -1c
.RI "\fBInhabitants\fP"
.br
.ti -1c
.RI "\fBinitPredictors\fP"
.br
.ti -1c
.RI "\fBinplace\fP"
.br
.ti -1c
.RI "\fBInstance\fP"
.br
.ti -1c
.RI "\fBj\fP"
.br
.ti -1c
.RI "\fBkind\fP"
.br
.ti -1c
.RI "\fBKNMI\fP = \fBKNMI_Resampler\fP(\fBpath\fP+'/uurgeg_290_2011\-2020\&.txt',\fBT_Columns\fP,\fBScaleArray\fP,header=28, Interval = '30min')"
.br
.ti -1c
.RI "dict \fBlambdaDict\fP"
.br
.ti -1c
.RI "dict \fBlambdaMap\fP"
.br
.ti -1c
.RI "\fBlegend\fP"
.br
.ti -1c
.RI "str \fBLog\fP = ''"
.br
.RI "Variable contains the generated Log, equal to code output in commandline\&. "
.ti -1c
.RI "\fBlongWindow\fP"
.br
.ti -1c
.RI "\fBlw\fP"
.br
.ti -1c
.RI "str \fBMODULE\fP = 'EtoP'"
.br
.RI "~~~~~~~~~~~~~~~~~~Milestone! "
.ti -1c
.RI "\fBmufit_html\fP = f\&.read()"
.br
.ti -1c
.RI "\fBnonexistent\fP"
.br
.ti -1c
.RI "\fBNormalizedEvents\fP = EventStudy\&.EventIndicer(threshold=float(config['eventdetection']['NormalizedEvents']))"
.br
.ti -1c
.RI "\fBNPColumns\fP = config['preprocessing']['NegativePower']\&.split(',')"
.br
.ti -1c
.RI "\fBOS\fP = os\&.environ\&.get('OS','')"
.br
.RI "Variable containing type of OS the code is running on\&. "
.ti -1c
.RI "\fBPandasDHWWrapper\fP"
.br
.ti -1c
.RI "\fBparser\fP = argparse\&.ArgumentParser()"
.br
.RI "Argument parser, filled with Commandline arguments\&. "
.ti -1c
.RI "\fBpath\fP = os\&.path\&.abspath(analysis\&.__file__)"
.br
.ti -1c
.RI "\fBPDC\fP = \fBdata\fP['Premainder']\&.resample('1h')\&.mean()\&.interpolate()\&.sort_values('Premainder',ascending=False)\&.reset_index(drop=\fBTrue\fP)"
.br
.ti -1c
.RI "\fBPdhw\fP"
.br
.ti -1c
.RI "\fBPdTtoV\fP"
.br
.ti -1c
.RI "\fBpiv\fP = pd\&.pivot_table(\fBdata\fP, \fBindex\fP=['hour'], \fBcolumns\fP=['day'], values=['Vdhwcal'])"
.br
.ti -1c
.RI "\fBpiv2\fP = piv\&.loc[:, (\fBpiv\fP != 0)\&.any(\fBaxis\fP=0)]"
.br
.ti -1c
.RI "\fBPPColumns\fP = config['preprocessing']['PositivePower']\&.split(',')"
.br
.ti -1c
.RI "\fBPredictedThermal\fP = pd\&.DataFrame(tp\&.Simulate(steps=tp\&.dataLength, err='HeatInput')[\-tp\&.dataLength:],\fBcolumns\fP=['index','err','HeatInput','HeatInput_pr','U','Ag','Ga','C'])"
.br
.ti -1c
.RI "\fBPVArea\fP = float(config['schil']['pvoppervlak'])"
.br
.ti -1c
.RI "\fBPVColumn\fP = config['preprocessing']['PVPanels']\&.split(',')"
.br
.ti -1c
.RI "\fBPVDC\fP = \fBdata\fP[['PVEfficiency']]\&.resample('1h')\&.mean()\&.interpolate()\&.sort_values('PVEfficiency',ascending=False)\&.reset_index(drop=\fBTrue\fP)"
.br
.ti -1c
.RI "\fBregressor\fP = LinearRegression()"
.br
.ti -1c
.RI "list \fBRevertArray\fP = []"
.br
.ti -1c
.RI "list \fBScaleArray\fP = [100*100\&.,1\&.0]"
.br
.ti -1c
.RI "\fBsd\fP"
.br
.ti -1c
.RI "\fBshortWindow\fP"
.br
.ti -1c
.RI "\fBSize\fP"
.br
.ti -1c
.RI "\fBSummerDetection\fP = pd\&.pivot_table(\fBdata\fP, \fBindex\fP=['hour'], \fBcolumns\fP=['day'], values= \fBThermalColumns\fP)"
.br
.ti -1c
.RI "\fBT1\fP"
.br
.ti -1c
.RI "\fBT2\fP"
.br
.ti -1c
.RI "list \fBT_Columns\fP = [' Q',' RH']"
.br
.ti -1c
.RI "\fBTDC\fP = \fBdata\fP[Ts]\&.resample('1h')\&.mean()\&.interpolate()\&.sort_values('dT',ascending=False)\&.reset_index(drop=\fBTrue\fP)"
.br
.ti -1c
.RI "\fBtest\fP = py2tex(\fBtex\fP,print_formula=False, print_latex=False, output='tex')\&.replace('$','')"
.br
.ti -1c
.RI "\fBtex\fP = \fBLambda2Tex\fP(\fBlambdaDict\fP[\fBi\fP])"
.br
.ti -1c
.RI "\fBThermalColumns\fP = config['preprocessing']['ThermalColumns']\&.split(',')"
.br
.ti -1c
.RI "dict \fBThermallambdaDict\fP"
.br
.ti -1c
.RI "dict \fBThermallambdaMap\fP"
.br
.ti -1c
.RI "\fBtitle\fP"
.br
.ti -1c
.RI "\fBtp\fP = \fBMultiFitter\fP(\fBInstance\fP,\fBlambdaMap\fP=\fBThermallambdaMap\fP,\fBlambdaDict\fP=\fBThermallambdaDict\fP,verbose=2)"
.br
.ti -1c
.RI "\fBTrue\fP"
.br
.ti -1c
.RI "\fBtype\fP"
.br
.ti -1c
.RI "int \fBVerbosity\fP = 1"
.br
.RI "For which level of knowledge to generate a report\&.ssss\&. "
.ti -1c
.RI "\fBverbosityLimit\fP"
.br
.ti -1c
.RI "tuple \fBwhite\fP = (255, 255, 255, 255)"
.br
.RI "Defining the color white for latex\&. "
.ti -1c
.RI "\fBX\fP = \fBdata\fP[['dT']]\&.interpolate()\&.bfill()\&.ffill()"
.br
.ti -1c
.RI "\fBy\fP = \fBdata\fP[['HeatInput']]"
.br
.ti -1c
.RI "\fBy_pred\fP = regressor\&.predict(\fBX\fP)"
.br
.ti -1c
.RI "list \fByear\fP = data\&.index[0]\&.year"
.br
.in -1c
.SH "Detailed Description"
.PP 
Defines the smart meter (pre)processor\&. 
.SH "Function Documentation"
.PP 
.SS "AnalysisDealer ( data,  analysis)"

.PP
.nf
Apply all user defined functions from analysis\&.py to data

@param data  Standardized input (pandas)dataframe\&.
@param analysis  a list of [[name:function],] of user defined functions

@return data the transformed dataframe
.fi
.PP
 
.PP
Definition at line \fB709\fP of file \fBpreProcessor\&.py\fP\&.
.PP
References \fBLogReport()\fP\&.
.SS "Carnot ( Tc,  Th)"

.PP
.nf
Calculate Carnot efficiency\&.

@param Tc  cold temperature in celsius\&.
@param Th  hot temperature in celsius\&.

@return Carnot efficiency
.fi
.PP
 
.PP
Definition at line \fB534\fP of file \fBpreProcessor\&.py\fP\&.
.SS "COP ( Pth,  Pel)"

.PP
.nf
Calculate Coefficient of Performance\&.

@param Pth  Thermal power units do not matter as long as they are both the same\&.
@param Pel  Electrical power, units do not matter as long as they are the same\&.

@return Coefficient of Performance
.fi
.PP
 
.PP
Definition at line \fB545\fP of file \fBpreProcessor\&.py\fP\&.
.SS "DerivedCategory ( trends,  newtrend,  CategoryWeights,  Verbose = \fR0\fP)"

.PP
.nf
Derive categories from initial guesses\&.

@param trends  The base trend from which to derive
@param newtrend  The derived trends which categories still need to be determined
@param CategoryWeights  The original category weights used for base trends, which will derive to new trends
@param Verbose  Verbosity switch for debugging

@return the same dataframe as trends but with newtrends added and with derived categories
.fi
.PP
 
.PP
Definition at line \fB670\fP of file \fBpreProcessor\&.py\fP\&.
.PP
Referenced by \fBProcessData()\fP\&.
.SS "EnvironmentTemperatureCheck ( df,  ROCLimit = \fR30\&.0/(12\&.0*60*60)\fP,  ULimit = \fR50\&.0\fP,  LLimit = \fR\-15\&.0\fP,  VERBOSE = \fR0\fP)"

.PP
Definition at line \fB359\fP of file \fBpreProcessor\&.py\fP\&.
.PP
References \fBlinint()\fP\&.
.SS "EventCategorizerFcn ( categories,  data)"

.PP
Summarizes all detected events to a limited group of categories, does the same as internal class function EventCategorizer but requires data\&. 
.PP
\fBParameters\fP
.RS 4
\fIcategories\fP a list of name:category to translate any column to a new category 
.br
\fIdata\fP a list of input data to categorize\&.
.RE
.PP
\fBReturns\fP
.RS 4
A new dataframe with events linked to categories 
.RE
.PP

.PP
Definition at line \fB242\fP of file \fBpreProcessor\&.py\fP\&.
.SS "fracH ( dt)"

.PP
.nf
Calculate the fraction of an hour, for interpolation\&.

@param dt datetime time object

@return decimal number between 0 and 24
.fi
.PP
 
.PP
Definition at line \fB455\fP of file \fBpreProcessor\&.py\fP\&.
.PP
Referenced by \fBPandasDHWWrapper()\fP\&.
.SS "KNMI_Resampler ( FileName,  T_Columns,  ScaleArray,  RevertArray = \fRNone\fP,  Interval = \fR'5min'\fP,  header = \fR28\fP,  Export = \fRFalse\fP,  plot = \fRFalse\fP)"

.PP
KNMI file reader with different output modi\&. 
.PP
\fBParameters\fP
.RS 4
\fIFileName\fP the filename with KNMI data to open, can include the path 
.br
\fIT_Columns\fP Time independent columns; the code needs to be aware of these in order to correctly interpolate\&. Array of strings\&.1 
.br
\fIScaleArray\fP Scales T_Columns, amount of items should match T_Columns 
.br
\fIRevertArray\fP Revert T_Columns through the scalars given here, amount of items should match T_Columns 
.br
\fIInterval\fP Time interval to interpolate or extrapolate towards\&. Can be a string like 5s, 5min, 1h, 1d, etc\&. 
.br
\fIheader\fP Number of lines to skip for the header line\&. Open the input file to find this\&. 
.br
\fIExport\fP If the resulting data needs to be exported to \&.CSV for future use or not\&. True or False 
.br
\fIplot\fP If set to True, a plot will be opened on completion\&.
.RE
.PP
\fBReturns\fP
.RS 4
A Pandas dataFrame transformed as configured 
.RE
.PP

.PP
Definition at line \fB581\fP of file \fBpreProcessor\&.py\fP\&.
.PP
References \fBTimeDivision()\fP\&.
.SS "Lambda2Tex ( lmd,  VERBOSE = \fR0\fP)"

.PP
.nf
Convert Lambda system of equations to latex

@param lmd  lambda function to convert
@param VERBOSE  retardcounter higher = less retarded

@return the converted equation in tex format
.fi
.PP
 
.PP
Definition at line \fB642\fP of file \fBpreProcessor\&.py\fP\&.
.SS "latex_to_img ( tex)"

.PP
.nf
Convert Latex expression to \&.png image

@param tex  the latex expression to convert to an image

@return an html compatible image? (check this!)
.fi
.PP
 
.PP
Definition at line \fB621\fP of file \fBpreProcessor\&.py\fP\&.
.SS "linint ( x1,  x2,  y1,  y2)"

.PP
.nf
Linear interpolation\&.

@param x1  value  (x2-x1)
@param x2  value  (x2-x1)
@param y1  value  delta = y2-y1
@param y2  value  delta = y2-y1

@return x2-x1 frames interpolated between y2 and y1
.fi
.PP
 
.PP
Definition at line \fB317\fP of file \fBpreProcessor\&.py\fP\&.
.PP
Referenced by \fBEnvironmentTemperatureCheck()\fP, and \fBRepairCumulatives()\fP\&.
.SS "logFigure ( title,  data,  Instance,  fig = \fRNone\fP,  sort = \fRNone\fP,  kind = \fRNone\fP,  verbosityLimit = \fRNone\fP)"

.PP
.nf
Add figure to the created log\&. And make sure it is rendered properly in HTML

@param title  the name of the figure under which it will be saved
@param data  the data to plot in the figure
@param fig  the figure object to plot, to allow customization but still end up in log/report\&.
@param sort  If the data to be plotted needs to be sorted or not, generates time-duration curves\&.
@param kind  type of matplotlib plot to generate (line, bar, etc\&.)

@param return  Adds figure to Log, either HTML or a link to the output figure\&.
.fi
.PP
 
.PP
Definition at line \fB500\fP of file \fBpreProcessor\&.py\fP\&.
.PP
References \fBLogReport()\fP\&.
.PP
Referenced by \fBProcessData()\fP\&.
.SS "LogReport ( msg,  verbosityLimit = \fRNone\fP)"

.PP
.nf
Function to unify logging, messaging, errors and report generation\&.

@param msg  Message to append to log or report
@param verbosityLimit The verbosity number connected to this message\&.

@return sets Log, Verbosity and Headers for every message
.fi
.PP
 
.PP
Definition at line \fB478\fP of file \fBpreProcessor\&.py\fP\&.
.PP
Referenced by \fBAnalysisDealer()\fP, \fBlogFigure()\fP, and \fBProcessData()\fP\&.
.SS "main ()"

.PP
Definition at line \fB1505\fP of file \fBpreProcessor\&.py\fP\&.
.PP
References \fBProcessData()\fP\&.
.SS "PandasDHWWrapper ( x,  Inhabitants = \fR1\fP)"

.PP
.nf
Wrap for Domestic Hot Water empirical equation for Pandas Apply\&.

@param x  a pandas dataframe to which DHW will be appended
@param Inhabitants  amount of inhabitants for which to generate a DHW profile

@return DHW profile for 
.fi
.PP
 
.PP
Definition at line \fB467\fP of file \fBpreProcessor\&.py\fP\&.
.PP
References \fBfracH()\fP, and \fBStochastic_Usage()\fP\&.
.SS "PdTtoV ( x,  T1,  T2,  Pdhw)"

.PP
.nf
Calculate DHW flow rate based on temperature difference and power\&.

@param x  series with power of domestic hot water
@param T1  value  (x2-x1)
@param T2  value  delta = y2-y1
@param y2  value  delta = y2-y1

@return x2-x1 frames interpolated between y2 and y1
.fi
.PP
 
.PP
Definition at line \fB441\fP of file \fBpreProcessor\&.py\fP\&.
.SS "ProcessData ()"

.PP
Example main to run if file is not being imported\&. 
.PP
Definition at line \fB756\fP of file \fBpreProcessor\&.py\fP\&.
.PP
References \fBDerivedCategory()\fP, \fBlogFigure()\fP, \fBLogReport()\fP, and \fBRepairCumulatives()\fP\&.
.PP
Referenced by \fBmain()\fP\&.
.SS "RepairCumulatives ( df,  VERBOSE = \fR0\fP)"

.PP
.nf
Repair cumulative trends from smart meter data\&.

@param df  input cumulative trends dataframe to repair
@param VERBOSE  verbosity switch to generate reports for different levels of knowledge

@return dataframe with actually cumulative trends\&.
.fi
.PP
 
.PP
Definition at line \fB398\fP of file \fBpreProcessor\&.py\fP\&.
.PP
References \fBlinint()\fP\&.
.PP
Referenced by \fBProcessData()\fP\&.
.SS "SimilarityCheck ( df,  data,  corrector,  ULimit = \fR50\&.0\fP,  LLimit = \fR\-15\&.0\fP,  ROCLimit = \fR30\&.0/(12\&.0*60*60)\fP,  VERBOSE = \fR0\fP)"

.PP
.nf
General sanity and similarity check

@param df  base dataframe containing all series to work with
@param data  name of column in dataframe which needs to be corrected
@param corrector  name of column in dataframe which can be used to correct data
@param ULimit  the upper limit, exceeding this value means that values from corrector will be taken
@param LLimit  the lower limit, going below this value means that values from corrector will be taken
@param ROCLimit  if this Rate Of Change is exceeded, values from corrector are taken
@param VERBOSE  if this value is bigger the 0, corrected values will be reported in the log with more details

@return The original dataframe but with the data column fixed according to above  rules\&.
.fi
.PP
 
.PP
Definition at line \fB332\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Stochastic_Usage ( H,  Size = \fR1\&.0\fP)"

.PP
.nf
Empirical equation for Domestic Hot Water usage\&.

@param H  Hour of the day for which to get the L/h value
@param Size  size of household, number of inhabitants

@return  A new dataframe with events linked to categories

.fi
.PP
 
.PP
Definition at line \fB299\fP of file \fBpreProcessor\&.py\fP\&.
.PP
Referenced by \fBPandasDHWWrapper()\fP\&.
.SS "TimeDivision ( df,  Columns,  scaleArray = \fRNone\fP,  reverse = \fRFalse\fP)"

.PP
.nf
Find delta in dataset and divide Columns by time\&.

@param df  input dataset containing columns to divide by time
@param Columns  Columns to divide by time\&. Delta will be detected automatically
@param scaleArray  Scaling to apply when dividing by time
@param reverse  Reverse the operation or not\&.

@return df  return the transformed dataframe\&. Calling same function with identical arguments but reverse = True returns to the original\&.
.fi
.PP
 
.PP
Definition at line \fB559\fP of file \fBpreProcessor\&.py\fP\&.
.PP
Referenced by \fBKNMI_Resampler()\fP\&.
.SS "VisualizeEvent ( df,  event,  Instance,  Extra = \fRNone\fP,  columns = \fRNone\fP,  Size = \fRNone\fP,  Type = \fR'default'\fP,  Save = \fR\fBTrue\fP\fP)"

.PP
Summarizes all detected events to a limited group of categories\&. 
.PP
\fBParameters\fP
.RS 4
\fIevent\fP finish this!!
.RE
.PP
\fBReturns\fP
.RS 4
A new dataframe with events linked to categories 
.RE
.PP

.PP
Definition at line \fB258\fP of file \fBpreProcessor\&.py\fP\&.
.SH "Variable Documentation"
.PP 
.SS "action"

.PP
Ignore FutureWarning errors, floods log\&. 
.PP
Definition at line \fB77\fP of file \fBpreProcessor\&.py\fP\&.
.SS "All"

.PP
Definition at line \fB1207\fP of file \fBpreProcessor\&.py\fP\&.
.SS "alpha"

.PP
Definition at line \fB1235\fP of file \fBpreProcessor\&.py\fP\&.
.SS "ambiguous"

.PP
Definition at line \fB1452\fP of file \fBpreProcessor\&.py\fP\&.
.SS "args = parser\&.parse_args()"

.PP
Instantiate the parser\&. 
.PP
Definition at line \fB98\fP of file \fBpreProcessor\&.py\fP\&.
.SS "axis"

.PP
Definition at line \fB976\fP of file \fBpreProcessor\&.py\fP\&.
.SS "backend"

.PP
plotting backend for pandas 
.PP
Definition at line \fB86\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list BaseWeights"
\fBInitial value:\fP
.nf
1 =  [["Combined_Categories", "User_Electric", "User_Thermal", "Building_thermal", "Installation_Electric", "Installation_Thermal", "Weather_thermal"],
2                 ["Tlive", 0, 0\&.9, 0\&.05, 0, 0\&.05, 0],
3                 ["Ttraffic", 0, 0\&.5, 0, 0, 0\&.2, 0\&.3],
4                 ["Tambient", 0, 0\&.5, 0, 0, 0\&.2, 0\&.3],
5                 ["Emachine", 0\&.1, 0\&.1, 0\&.2, 0\&.5, 0\&.1, 0]]
.PP
.fi

.PP
Definition at line \fB663\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Bestparams = fmf\&.constants"

.PP
Definition at line \fB1154\fP of file \fBpreProcessor\&.py\fP\&.
.SS "bestSimulation = pd\&.DataFrame(fmf\&.Simulate(steps=fmf\&.dataLength, err='Tavg')[\-fmf\&.dataLength:],\fBcolumns\fP=['index','err','Tavg','Tavg_pr','U','Ag','Ga','C'])"

.PP
Definition at line \fB1159\fP of file \fBpreProcessor\&.py\fP\&.
.SS "category"

.PP
Definition at line \fB77\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list CategoryWeights = [['Combined_Categories', 'User_Electric', 'User_Thermal', 'Building_thermal', 'Installation_Electric', 'Installation_Thermal', 'Weather_thermal']]"

.PP
Definition at line \fB662\fP of file \fBpreProcessor\&.py\fP\&.
.SS "cEventCfg = config['eventdetection']['OtherEvents']\&.split(',')"

.PP
Definition at line \fB1408\fP of file \fBpreProcessor\&.py\fP\&.
.SS "chained_assignment"

.PP
turn of error reporting for chained assignments 
.PP
Definition at line \fB88\fP of file \fBpreProcessor\&.py\fP\&.
.SS "color"

.PP
Definition at line \fB1075\fP of file \fBpreProcessor\&.py\fP\&.
.SS "columns"

.PP
Definition at line \fB1007\fP of file \fBpreProcessor\&.py\fP\&.
.SS "COPDC = \fBdata\fP[['COP']]\&.resample('1h')\&.mean()\&.interpolate()\&.sort_values('COP',ascending=False)\&.reset_index(drop=\fBTrue\fP)"

.PP
Definition at line \fB1232\fP of file \fBpreProcessor\&.py\fP\&.
.SS "data = data\&.resample(config['preprocessing']['ResampleTime'])\&.mean()\&.interpolate()"

.PP
~~~~~~~~~~~~~~~~~~Milestone! 
.PP
Definition at line \fB901\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dataAfternoon = \fBTimeDivision\fP(\fBdataHourly\fP,timeDivisionArray)"

.PP
Definition at line \fB1486\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dataDaily = \fBTimeDivision\fP(\fBdata\fP,timeDivisionArray)"

.PP
Definition at line \fB1463\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dataEvening = \fBTimeDivision\fP(\fBdataHourly\fP,timeDivisionArray)"

.PP
Definition at line \fB1491\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dataHourly = \fBTimeDivision\fP(\fBdata\fP,timeDivisionArray)"

.PP
Definition at line \fB1457\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dataMonthly = \fBTimeDivision\fP(\fBdata\fP,timeDivisionArray)"

.PP
Definition at line \fB1475\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dataMorning = \fBTimeDivision\fP(\fBdataHourly\fP,timeDivisionArray)"

.PP
Definition at line \fB1481\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dataNight = \fBTimeDivision\fP(\fBdataHourly\fP,timeDivisionArray)"

.PP
Definition at line \fB1496\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dataWeekly = \fBTimeDivision\fP(\fBdata\fP,timeDivisionArray)"

.PP
Definition at line \fB1469\fP of file \fBpreProcessor\&.py\fP\&.
.SS "tuple dda = degreeDays_delta_annemarie\&.sum()"

.PP
Definition at line \fB995\fP of file \fBpreProcessor\&.py\fP\&.
.SS "ddi = degreeDays_indoor\&.sum()"

.PP
Definition at line \fB991\fP of file \fBpreProcessor\&.py\fP\&.
.SS "ddo = degreeDays_outdoor\&.sum()"

.PP
Definition at line \fB993\fP of file \fBpreProcessor\&.py\fP\&.
.SS "default"

.PP
Definition at line \fB95\fP of file \fBpreProcessor\&.py\fP\&.
.SS "tuple degreeDays_delta_annemarie = (\fBdata\fP['Tavg'] \- \fBdata\fP['Tamb'])\&.resample('1d')\&.mean()\&.interpolate()"

.PP
Definition at line \fB994\fP of file \fBpreProcessor\&.py\fP\&.
.SS "degreeDays_indoor = \fBdata\fP['Tavg']\&.resample('1d')\&.mean()\&.interpolate()\&.apply(lambda x: 18 \- x if x > 18 else 0)"

.PP
Definition at line \fB990\fP of file \fBpreProcessor\&.py\fP\&.
.SS "degreeDays_outdoor = \fBdata\fP['Tamb']\&.resample('1d')\&.mean()\&.interpolate()\&.apply(lambda x: 18 \- x if x > 18 else 0)"

.PP
Definition at line \fB992\fP of file \fBpreProcessor\&.py\fP\&.
.SS "df = pd\&.DataFrame(fmf\&.error,\fBcolumns\fP=['index','error','c0','c1'])"

.PP
Definition at line \fB1139\fP of file \fBpreProcessor\&.py\fP\&.
.SS "DHSummerSlice = \fBdata\fP[\fBThermalColumns\fP]\&.loc['{}\-05\-01'\&.format(\fByear\fP) : '{}\-07\-31'\&.format(\fByear\fP)]"

.PP
Definition at line \fB1297\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list dhw = [[\fBindex\fP,\fBdhw1\fP], [\fBindex\fP,\fBdhw2\fP], [\fBindex\fP,\fBdhw3\fP], [\fBindex\fP, \fBdhw4\fP], [\fBindex\fP, \fBdhw5\fP], [\fBindex\fP, \fBdhw6\fP], [\fBindex\fP, \fBdhw7\fP], [\fBindex\fP, \fBdhw8\fP]]"

.PP
Domestic hot water lookup table\&. 
.PP
Definition at line \fB753\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list dhw1 = []"

.PP
Definition at line \fB732\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list dhw2 = []"

.PP
Definition at line \fB733\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list dhw3 = []"

.PP
Definition at line \fB734\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list dhw4 = []"

.PP
Definition at line \fB735\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list dhw5 = []"

.PP
Definition at line \fB736\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list dhw6 = []"

.PP
Definition at line \fB737\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list dhw7 = []"

.PP
Definition at line \fB738\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list dhw8 = []"

.PP
Definition at line \fB739\fP of file \fBpreProcessor\&.py\fP\&.
.SS "DHW_Baseline = piv\&.mean(\fBaxis\fP=1)"

.PP
Definition at line \fB1322\fP of file \fBpreProcessor\&.py\fP\&.
.SS "DHWColumns = config['preprocessing']['DHWColumns']\&.split(',')"

.PP
Definition at line \fB1292\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dt"

.PP
Definition at line \fB1140\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dwstateColumns = config['preprocessing']['DoorWindowStates']\&.split(',')"

.PP
Definition at line \fB1033\fP of file \fBpreProcessor\&.py\fP\&.
.SS "E_Baseline = Epiv\&.mean(\fBaxis\fP=1)"

.PP
Definition at line \fB1266\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Epiv = pd\&.pivot_table(\fBdata\fP, \fBindex\fP=['hour'], \fBcolumns\fP=['day'], values=['Premainder'])"

.PP
Definition at line \fB1262\fP of file \fBpreProcessor\&.py\fP\&.
.SS "errors"

.PP
Definition at line \fB1209\fP of file \fBpreProcessor\&.py\fP\&.
.SS "EventConfig = config['eventdetection'][\fBi\fP]\&.split(',')"

.PP
Definition at line \fB1411\fP of file \fBpreProcessor\&.py\fP\&.
.SS "EventData = EventStudy\&.data[EventStudy\&.eventcolumns]"

.PP
Definition at line \fB1424\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list Events = []"

.PP
Definition at line \fB1409\fP of file \fBpreProcessor\&.py\fP\&.
.SS "EventStudy = \fBEventor\fP(data\&.loc[:, data\&.columns != 'DateTime'], VERBOSE=5)"

.PP
Definition at line \fB1000\fP of file \fBpreProcessor\&.py\fP\&.
.SS "str figname = '{}_data_processed'\&.format(config['preprocessing']['Filename']\&.split('\&.')[0])"

.PP
Definition at line \fB1423\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Finalcategories = pd\&.DataFrame(\fBCategoryWeights\fP[1:],\fBcolumns\fP=\fBCategoryWeights\fP[0], \fBindex\fP=[\fBi\fP[0] for \fBi\fP in \fBCategoryWeights\fP[1:]])\&.drop('Combined_Categories',\fBaxis\fP=1)"

.PP
Definition at line \fB1440\fP of file \fBpreProcessor\&.py\fP\&.
.SS "fmf = \fBMultiFitter\fP(\fBInstance\fP,\fBlambdaMap\fP=\fBlambdaMap\fP,\fBlambdaDict\fP=\fBlambdaDict\fP,verbose=2)"

.PP
Definition at line \fB1135\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Function_List = getmembers(analysis, isfunction)"

.PP
~~~~~~~~~~~~~~~~~ USER ANALYSIS FUNCTION MAGIC ~~~~~~~~~~~~~~~~~#### 
.PP
Definition at line \fB966\fP of file \fBpreProcessor\&.py\fP\&.
.SS "gas = int(config['schil']['gas'])"

.PP
Definition at line \fB1014\fP of file \fBpreProcessor\&.py\fP\&.
.SS "GenericConfig = config['eventdetection']['GenericEvents']\&.split(',')"

.PP
Definition at line \fB1001\fP of file \fBpreProcessor\&.py\fP\&.
.SS "str Headers = '# Table Of Content\\n ' + '__'*100"

.PP
Headers of document\&. Created Table of Content\&. 
.PP
Definition at line \fB728\fP of file \fBpreProcessor\&.py\fP\&.
.SS "help"

.PP
Definition at line \fB93\fP of file \fBpreProcessor\&.py\fP\&.
.SS "HPEColumns = config['preprocessing']['HeatPumpElectric']\&.split(',')"

.PP
Definition at line \fB1220\fP of file \fBpreProcessor\&.py\fP\&.
.SS "HPTColumns = config['preprocessing']['HeatPumpThermal']\&.split(',')"

.PP
Definition at line \fB1221\fP of file \fBpreProcessor\&.py\fP\&.
.SS "i"

.PP
Definition at line \fB1402\fP of file \fBpreProcessor\&.py\fP\&.
.SS "index = []"

.PP
Definition at line \fB740\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Indoor_temperatures = config['preprocessing']['IndoorTemperatures']\&.split(',')"

.PP
Definition at line \fB975\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Inhabitants"

.PP
Definition at line \fB1300\fP of file \fBpreProcessor\&.py\fP\&.
.SS "initPredictors"

.PP
Definition at line \fB1136\fP of file \fBpreProcessor\&.py\fP\&.
.SS "inplace"

.PP
Definition at line \fB1182\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Instance"

.PP
Definition at line \fB1160\fP of file \fBpreProcessor\&.py\fP\&.
.SS "j"

.PP
Definition at line \fB1419\fP of file \fBpreProcessor\&.py\fP\&.
.SS "kind"

.PP
Definition at line \fB1443\fP of file \fBpreProcessor\&.py\fP\&.
.SS "KNMI = \fBKNMI_Resampler\fP(\fBpath\fP+'/uurgeg_290_2011\-2020\&.txt',\fBT_Columns\fP,\fBScaleArray\fP,header=28, Interval = '30min')"

.PP
Definition at line \fB925\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dict lambdaDict"
\fBInitial value:\fP
.nf
1 =  {"Qtr": lambda Tamb, Tavg, U: (Tamb\-Tavg)*0\&.001/ U,
2                       "Qcv": lambda HeatInput: HeatInput,
3                       "Qsol": lambda P_sun, Ag, Ga: P_sun*0\&.001*Ag*Ga,
4                       "dTobj": lambda Qsol, Qcv, Qtr, dt, C: (Qtr+Qcv+Qsol)*dt/C,
5                       "Tavg": lambda Tavg, dTobj: Tavg + dTobj}
.PP
.fi

.PP
Definition at line \fB1097\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dict lambdaMap"
\fBInitial value:\fP
.nf
1 =  {"Qtr": ["Tamb","Tavg","$U"],
2                      "Qcv":["HeatInput"],
3                      "Qsol":["P\-sun","*Ag","$Ga"], # where Ag = glass area and Ga = solar irradiance factor, for solver!
4                      "dTobj":["Qsol","Qcv","Qtr","dt","$C"],
5                      "Tavg":["Tavg","dTobj"]}
.PP
.fi

.PP
Definition at line \fB1091\fP of file \fBpreProcessor\&.py\fP\&.
.SS "legend"

.PP
Definition at line \fB1060\fP of file \fBpreProcessor\&.py\fP\&.
.SS "str Log = ''"

.PP
Variable contains the generated Log, equal to code output in commandline\&. 
.PP
Definition at line \fB726\fP of file \fBpreProcessor\&.py\fP\&.
.SS "longWindow"

.PP
Definition at line \fB1007\fP of file \fBpreProcessor\&.py\fP\&.
.SS "lw"

.PP
Definition at line \fB1060\fP of file \fBpreProcessor\&.py\fP\&.
.SS "str MODULE = 'EtoP'"

.PP
~~~~~~~~~~~~~~~~~~Milestone! ~~~~~~~~~~~~~~~~~ USER ANALYSIS FUNCTION MAGIC ~~~~~~~~~~~~~~~~~#### 
.PP
Definition at line \fB904\fP of file \fBpreProcessor\&.py\fP\&.
.SS "mufit_html = f\&.read()"

.PP
Definition at line \fB1210\fP of file \fBpreProcessor\&.py\fP\&.
.SS "nonexistent"

.PP
Definition at line \fB1452\fP of file \fBpreProcessor\&.py\fP\&.
.SS "NormalizedEvents = EventStudy\&.EventIndicer(threshold=float(config['eventdetection']['NormalizedEvents']))"

.PP
Definition at line \fB1396\fP of file \fBpreProcessor\&.py\fP\&.
.SS "NPColumns = config['preprocessing']['NegativePower']\&.split(',')"

.PP
Definition at line \fB1252\fP of file \fBpreProcessor\&.py\fP\&.
.SS "OS = os\&.environ\&.get('OS','')"

.PP
Variable containing type of OS the code is running on\&. 
.PP
Definition at line \fB82\fP of file \fBpreProcessor\&.py\fP\&.
.SS "PandasDHWWrapper"

.PP
Definition at line \fB1300\fP of file \fBpreProcessor\&.py\fP\&.
.SS "parser = argparse\&.ArgumentParser()"

.PP
Argument parser, filled with Commandline arguments\&. 
.PP
Definition at line \fB91\fP of file \fBpreProcessor\&.py\fP\&.
.SS "str path = os\&.path\&.abspath(analysis\&.__file__)"

.PP
Definition at line \fB921\fP of file \fBpreProcessor\&.py\fP\&.
.SS "PDC = \fBdata\fP['Premainder']\&.resample('1h')\&.mean()\&.interpolate()\&.sort_values('Premainder',ascending=False)\&.reset_index(drop=\fBTrue\fP)"

.PP
Definition at line \fB1350\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Pdhw"

.PP
Definition at line \fB1298\fP of file \fBpreProcessor\&.py\fP\&.
.SS "PdTtoV"

.PP
Definition at line \fB1298\fP of file \fBpreProcessor\&.py\fP\&.
.SS "piv = pd\&.pivot_table(\fBdata\fP, \fBindex\fP=['hour'], \fBcolumns\fP=['day'], values=['Vdhwcal'])"

.PP
Definition at line \fB1317\fP of file \fBpreProcessor\&.py\fP\&.
.SS "piv2 = piv\&.loc[:, (\fBpiv\fP != 0)\&.any(\fBaxis\fP=0)]"

.PP
Definition at line \fB1318\fP of file \fBpreProcessor\&.py\fP\&.
.SS "PPColumns = config['preprocessing']['PositivePower']\&.split(',')"

.PP
Definition at line \fB1251\fP of file \fBpreProcessor\&.py\fP\&.
.SS "PredictedThermal = pd\&.DataFrame(tp\&.Simulate(steps=tp\&.dataLength, err='HeatInput')[\-tp\&.dataLength:],\fBcolumns\fP=['index','err','HeatInput','HeatInput_pr','U','Ag','Ga','C'])"

.PP
Definition at line \fB1172\fP of file \fBpreProcessor\&.py\fP\&.
.SS "PVArea = float(config['schil']['pvoppervlak'])"

.PP
Definition at line \fB1045\fP of file \fBpreProcessor\&.py\fP\&.
.SS "PVColumn = config['preprocessing']['PVPanels']\&.split(',')"

.PP
Definition at line \fB1044\fP of file \fBpreProcessor\&.py\fP\&.
.SS "PVDC = \fBdata\fP[['PVEfficiency']]\&.resample('1h')\&.mean()\&.interpolate()\&.sort_values('PVEfficiency',ascending=False)\&.reset_index(drop=\fBTrue\fP)"

.PP
Definition at line \fB1057\fP of file \fBpreProcessor\&.py\fP\&.
.SS "regressor = LinearRegression()"

.PP
Definition at line \fB1071\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list RevertArray = []"

.PP
Definition at line \fB920\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list ScaleArray = [100*100\&.,1\&.0]"

.PP
Definition at line \fB919\fP of file \fBpreProcessor\&.py\fP\&.
.SS "sd"

.PP
Definition at line \fB1007\fP of file \fBpreProcessor\&.py\fP\&.
.SS "shortWindow"

.PP
Definition at line \fB1007\fP of file \fBpreProcessor\&.py\fP\&.
.SS "Size"

.PP
Definition at line \fB1402\fP of file \fBpreProcessor\&.py\fP\&.
.SS "SummerDetection = pd\&.pivot_table(\fBdata\fP, \fBindex\fP=['hour'], \fBcolumns\fP=['day'], values= \fBThermalColumns\fP)"

.PP
Definition at line \fB1310\fP of file \fBpreProcessor\&.py\fP\&.
.SS "T1"

.PP
Definition at line \fB1298\fP of file \fBpreProcessor\&.py\fP\&.
.SS "T2"

.PP
Definition at line \fB1298\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list T_Columns = [' Q',' RH']"

.PP
Definition at line \fB918\fP of file \fBpreProcessor\&.py\fP\&.
.SS "TDC = \fBdata\fP[Ts]\&.resample('1h')\&.mean()\&.interpolate()\&.sort_values('dT',ascending=False)\&.reset_index(drop=\fBTrue\fP)"

.PP
Definition at line \fB1367\fP of file \fBpreProcessor\&.py\fP\&.
.SS "test = py2tex(\fBtex\fP,print_formula=False, print_latex=False, output='tex')\&.replace('$','')"

.PP
Definition at line \fB1129\fP of file \fBpreProcessor\&.py\fP\&.
.SS "tex = \fBLambda2Tex\fP(\fBlambdaDict\fP[\fBi\fP])"

.PP
Definition at line \fB1124\fP of file \fBpreProcessor\&.py\fP\&.
.SS "ThermalColumns = config['preprocessing']['ThermalColumns']\&.split(',')"

.PP
Definition at line \fB1013\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dict ThermallambdaDict"
\fBInitial value:\fP
.nf
1 =  {"Qtr": lambda Tamb, Tavg, U: (Tamb\-Tavg)*0\&.001/ U,
2                              "HeatInput": lambda dT, C, dt, Qtr, Qsol: ((dT*C/dt) \- Qtr \- Qsol)*0\&.001,
3                              "Qsol": lambda P_sun, Ag, Ga: P_sun*0\&.001*Ag*Ga,
4                              "dTobj": lambda dTobj: dTobj, # (Qtr+HeatInput+Qsol)*dt/C = dT,
5                              "Tavg": lambda Tavg, dTobj: Tavg + dTobj}
.PP
.fi

.PP
Definition at line \fB1110\fP of file \fBpreProcessor\&.py\fP\&.
.SS "dict ThermallambdaMap"
\fBInitial value:\fP
.nf
1 =  {"Qtr": ["Tamb","Tavg","$U"],
2                             "HeatInput":["dT", "$C", "dt", "Qtr", "Qsol"],
3                             "Qsol":["P\-sun","*Ag","$Ga"], # where Ag = glass area and Ga = solar irradiance factor, for solver!
4                             "dTobj":["dTobj"],
5                             "Tavg":["Tavg","dTobj"]}
.PP
.fi

.PP
Definition at line \fB1104\fP of file \fBpreProcessor\&.py\fP\&.
.SS "title"

.PP
Definition at line \fB1264\fP of file \fBpreProcessor\&.py\fP\&.
.SS "tp = \fBMultiFitter\fP(\fBInstance\fP,\fBlambdaMap\fP=\fBThermallambdaMap\fP,\fBlambdaDict\fP=\fBThermallambdaDict\fP,verbose=2)"

.PP
Definition at line \fB1168\fP of file \fBpreProcessor\&.py\fP\&.
.SS "True"

.PP
Definition at line \fB1060\fP of file \fBpreProcessor\&.py\fP\&.
.SS "type"

.PP
Definition at line \fB92\fP of file \fBpreProcessor\&.py\fP\&.
.SS "int Verbosity = 1"

.PP
For which level of knowledge to generate a report\&.ssss\&. 
.PP
Definition at line \fB730\fP of file \fBpreProcessor\&.py\fP\&.
.SS "verbosityLimit"

.PP
Definition at line \fB1160\fP of file \fBpreProcessor\&.py\fP\&.
.SS "tuple white = (255, 255, 255, 255)"

.PP
Defining the color white for latex\&. 
.PP
Definition at line \fB619\fP of file \fBpreProcessor\&.py\fP\&.
.SS "X = \fBdata\fP[['dT']]\&.interpolate()\&.bfill()\&.ffill()"

.PP
Definition at line \fB1069\fP of file \fBpreProcessor\&.py\fP\&.
.SS "y = \fBdata\fP[['HeatInput']]"

.PP
Definition at line \fB1070\fP of file \fBpreProcessor\&.py\fP\&.
.SS "y_pred = regressor\&.predict(\fBX\fP)"

.PP
Definition at line \fB1073\fP of file \fBpreProcessor\&.py\fP\&.
.SS "list year = data\&.index[0]\&.year"

.PP
Definition at line \fB1294\fP of file \fBpreProcessor\&.py\fP\&.
.SH "Author"
.PP 
Generated automatically by Doxygen for Smart Meter Interpreter Documentation from the source code\&.
